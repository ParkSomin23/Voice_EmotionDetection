{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EMO_3.Net.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMLe/5kEpzsuS7aSgqvSCyK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ParkSomin23/Voice_EmotionDetection/blob/master/EMO_3_Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fcy_hXjYlxef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "import time\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBUNgspwJzNj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from keras.utils import np_utils, to_categorical"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjRaAKWSCxX0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "592c7d65-cd89-472f-9fee-1b8d8e8ef51d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPJTbU4eUrDk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "ced77510-19d9-4ba9-8eb3-a0168529c767"
      },
      "source": [
        "classes = ['female_angry', 'female_disgust', 'female_fear', 'female_happy',\n",
        "       'female_neutral', 'female_sad', 'female_surprise', 'male_angry',\n",
        "       'male_disgust', 'male_fear', 'male_happy', 'male_neutral',\n",
        "       'male_sad', 'male_surprise']\n",
        "classes"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['female_angry',\n",
              " 'female_disgust',\n",
              " 'female_fear',\n",
              " 'female_happy',\n",
              " 'female_neutral',\n",
              " 'female_sad',\n",
              " 'female_surprise',\n",
              " 'male_angry',\n",
              " 'male_disgust',\n",
              " 'male_fear',\n",
              " 'male_happy',\n",
              " 'male_neutral',\n",
              " 'male_sad',\n",
              " 'male_surprise']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05HVtRH-J1QQ",
        "colab_type": "text"
      },
      "source": [
        "# Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOyrBQESl4wm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Emo2DNet(nn.Module):\n",
        "    def __init__(self, n):\n",
        "        super().__init__()\n",
        "        self.n = n\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size = (3, 9), padding=(1,4))\n",
        "        self.b_norm1 = nn.BatchNorm2d(32)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size = (3, 9), padding=(1,4))\n",
        "        self.b_norm2 = nn.BatchNorm2d(32)\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(32, 32, kernel_size = (3, 9), padding=(1,4))\n",
        "        self.b_norm3 = nn.BatchNorm2d(32)\n",
        "        \n",
        "        self.conv4 = nn.Conv2d(32, 32, kernel_size = (3, 9), padding=(1,4))\n",
        "        self.b_norm4 = nn.BatchNorm2d(32)\n",
        "        \n",
        "        #self.b_norm5 = nn.BatchNorm2d(32) #\n",
        "        \n",
        "        self.fc1 = nn.Linear(32*13, 14)\n",
        "        #self.fc2 = nn.Linear(64, 32)\n",
        "        #self.fc3 = nn.Linear(32, 14)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = nn.ReLU()(self.b_norm1(x))\n",
        "        x = nn.MaxPool2d(2)(x)\n",
        "        x = nn.Dropout2d(p=0.2)(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = nn.ReLU()(self.b_norm2(x))\n",
        "        x = nn.MaxPool2d(2)(x)\n",
        "        x = nn.Dropout2d(p=0.2)(x)\n",
        "        \n",
        "        x = self.conv3(x)\n",
        "        x = nn.ReLU()(self.b_norm1(x))\n",
        "        x = nn.MaxPool2d(2)(x)\n",
        "        x = nn.Dropout2d(p=0.2)(x)\n",
        "        \n",
        "        x = self.conv4(x)\n",
        "        x = nn.ReLU()(self.b_norm1(x))\n",
        "        x = nn.MaxPool2d(2)(x)\n",
        "        x = nn.Dropout2d(p=0.2)(x)\n",
        "        \n",
        "        x = x.view(-1, 32*13)\n",
        "        #x = nn.ReLU()(self.b_norm5(x))#\n",
        "        #x = nn.MaxPool1D(2)(x)#\n",
        "        x = self.fc1(x)\n",
        "        x = nn.Dropout(p=0.2)(x)\n",
        "        \n",
        "        #x = self.fc2(x)\n",
        "        #x = self.fc3(x)\n",
        "        \n",
        "        x = F.log_softmax(x, dim=1)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pULairDWraCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_correct = list(0. for i in range(14))\n",
        "class_total = list(0. for i in range(14))\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=5):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = model.state_dict()\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # 각 Epoch은 학습 단계와 검증 단계를 거침\n",
        "        for phase in ['train', 'valid']:\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "                model.train(True)  # 학습 모드 설정\n",
        "            else:\n",
        "                model.train(False)  # 검증 모드 설정\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # 데이터 반\n",
        "            for data in dataloaders[phase]:\n",
        "                # 입력 데이터 가져오기\n",
        "                inputs, labels = data\n",
        "\n",
        "                # 데이터를 Vaariable로 만듦\n",
        "                if torch.cuda.is_available():\n",
        "                    inputs = Variable(inputs.cuda())\n",
        "                    labels = Variable(labels.cuda())\n",
        "                else:\n",
        "                    inputs, labels = Variable(inputs), Variable(labels)\n",
        "\n",
        "                # 파라미터 기울기 초기화\n",
        "                optimizer.zero_grad()\n",
        "                \n",
        "                # forward\n",
        "                outputs = model(inputs.float())\n",
        "                _, preds = torch.max(outputs.data, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                if phase == 'valid':\n",
        "                  c = (preds == labels.data).squeeze(0)\n",
        "                  c = c.to('cpu')\n",
        "                  c = np.array(c).astype('int')\n",
        "\n",
        "                  for i in range(5): #6....? ㅠㅠ\n",
        "                    label = labels[i]\n",
        "                    # print(i, label)\n",
        "                    class_correct[label] = class_correct[label] + c[i]\n",
        "                    class_total[label] = class_total[label] + 1\n",
        "\n",
        "\n",
        "                # 학습 단계에서만 수행, 역전파 + 옵티마이즈(최적화)\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                # 통계\n",
        "                running_loss += loss.data\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss.item() / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.item() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # 모델 복사(Deep Copy)\n",
        "            if phase == 'valid' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = model.state_dict()\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    for i in range(14):\n",
        "      print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))\n",
        "\n",
        "    # 최적의 모델 가중치 로딩\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dyar0AQFwL0B",
        "colab_type": "text"
      },
      "source": [
        "# Print  confusion matriv heat map plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h36dFJPwV7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
        "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
        "    \n",
        "    Arguments\n",
        "    ---------\n",
        "    confusion_matrix: numpy.ndarray\n",
        "        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n",
        "        Similarly constructed ndarrays can also be used.\n",
        "    class_names: list\n",
        "        An ordered list of class names, in the order they index the given confusion matrix.\n",
        "    figsize: tuple\n",
        "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
        "        the second determining the vertical size. Defaults to (10,7).\n",
        "    fontsize: int\n",
        "        Font size for axes labels. Defaults to 14.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    matplotlib.figure.Figure\n",
        "        The resulting confusion matrix figure\n",
        "    \"\"\"\n",
        "    df_cm = pd.DataFrame(\n",
        "        confusion_matrix, index=class_names, columns=class_names, \n",
        "    )\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    try:\n",
        "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "    except ValueError:\n",
        "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
        "        \n",
        "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
        "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "# Gender recode function\n",
        "def gender(row):\n",
        "    if row == 'female_disgust' or 'female_fear' or 'female_happy' or 'female_sad' or 'female_surprise' or 'female_neutral':\n",
        "        return 'female'\n",
        "    elif row == 'male_angry' or 'male_fear' or 'male_happy' or 'male_sad' or 'male_surprise' or 'male_neutral' or 'male_disgust':\n",
        "        return 'male'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEAJz5-aaqNz",
        "colab_type": "text"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKvWfqioakq-",
        "colab_type": "text"
      },
      "source": [
        "# Dataset & DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZvRwZlhNZpq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class myDataset(Dataset):\n",
        "    def __init__(self, d, l):\n",
        "      self.d = d\n",
        "      self.l = l\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      data = self.d[idx]\n",
        "      data = np.transpose(data,(2,0,1))\n",
        "      l = self.l[idx].argmax()\n",
        "      #label = emo_dict[l]\n",
        "      #label = self.l[idx]\n",
        "      return data, l\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.d)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rp-7hhhJ3_M",
        "colab_type": "text"
      },
      "source": [
        "#MFCC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2MjbYNCf_6I",
        "colab_type": "text"
      },
      "source": [
        "1. Best val Acc: 0.453573\n",
        "2. Best val Acc: 0.103555\n",
        "\n",
        "ADAM \n",
        "1. Best val Acc: 0.46185"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2r9gv1FTC2HW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f3ff1cf0-25eb-460c-efd7-2cc2db156d1b"
      },
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "with open(\"/gdrive/My Drive/mfcc_crema.pkl\", 'rb') as f:\n",
        "    ref_c = pickle.load(f)\n",
        "\n",
        "with open(\"/gdrive/My Drive/mfcc_3.pkl\", 'rb') as f:\n",
        "    ref_3 = pickle.load(f)\n",
        "\n",
        "print(ref_c.shape)\n",
        "print(ref_3.shape)\n",
        "\n",
        "ref = pd.read_csv(\"/gdrive/My Drive/Data_path.csv\")\n",
        "ref = ref.drop(11586)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7062, 30, 216, 1)\n",
            "(4524, 30, 216, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPXXi94BEaDt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "612d63d4-abba-4ea6-818f-6ef2b92cdbd8"
      },
      "source": [
        "mfcc = np.concatenate((ref_3, ref_c), axis=0)\n",
        "mfcc.shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11586, 30, 216, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPub2gw5q2sT",
        "colab_type": "text"
      },
      "source": [
        "**1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IU5txNuKM78B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(mfcc, ref.labels, test_size=0.25, shuffle=True, random_state=42)\n",
        "\n",
        "\n",
        "# one hot encode the target \n",
        "lb = LabelEncoder()\n",
        "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
        "y_test = np_utils.to_categorical(lb.fit_transform(y_test))\n",
        "\n",
        "# Normalization as per the standard NN process\n",
        "mean = np.mean(X_train, axis=0)\n",
        "std = np.std(X_train, axis=0)\n",
        "\n",
        "X_train = (X_train - mean)/std\n",
        "X_test = (X_test - mean)/std"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XyvdbKKq6cO",
        "colab_type": "text"
      },
      "source": [
        "**2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dw0j-fcype29",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(mfcc, ref.labels, test_size=0.25, shuffle=True, random_state=42)\n",
        "\n",
        "\n",
        "# one hot encode the target \n",
        "lb = LabelEncoder()\n",
        "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
        "y_test = np_utils.to_categorical(lb.fit_transform(y_test))\n",
        "\n",
        "#other normalization\n",
        "max_data = np.max(X_train)\n",
        "min_data = np.min(X_train)\n",
        "X_train = (X_train-min_data)/(max_data-min_data+1e-6)\n",
        "X_train =  X_train-0.5\n",
        "\n",
        "max_data = np.max(X_test)\n",
        "min_data = np.min(X_test)\n",
        "X_test = (X_test-min_data)/(max_data-min_data+1e-6)\n",
        "X_test =  X_test-0.5"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pYd1fLarpfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft = Emo2DNet(30)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model_ft = model_ft.cuda()"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTxxODWlroti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.01\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer_ft = optim.Adam(model_ft.parameters())\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRP8pDajPAde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = myDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size= 6, shuffle=True)\n",
        "\n",
        "valid_dataset = myDataset(X_test, y_test)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size= 6, shuffle=True)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY8krfgZsxQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_sizes = {'train':len(train_loader.dataset),'valid':len(valid_loader.dataset)}\n",
        "dataloaders = {'train':train_loader,'valid':valid_loader}"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OG7jCXhrkTZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1f0a7cef-25d6-4b96-ffe4-b5386662e3c0"
      },
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=24)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/23\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.3711 Acc: 0.2402\n",
            "valid Loss: 0.3894 Acc: 0.2271\n",
            "\n",
            "Epoch 1/23\n",
            "----------\n",
            "train Loss: 0.3161 Acc: 0.3572\n",
            "valid Loss: 0.3992 Acc: 0.2223\n",
            "\n",
            "Epoch 2/23\n",
            "----------\n",
            "train Loss: 0.2946 Acc: 0.3972\n",
            "valid Loss: 0.3735 Acc: 0.2475\n",
            "\n",
            "Epoch 3/23\n",
            "----------\n",
            "train Loss: 0.2800 Acc: 0.4223\n",
            "valid Loss: 0.3682 Acc: 0.2620\n",
            "\n",
            "Epoch 4/23\n",
            "----------\n",
            "train Loss: 0.2705 Acc: 0.4340\n",
            "valid Loss: 0.3668 Acc: 0.2741\n",
            "\n",
            "Epoch 5/23\n",
            "----------\n",
            "train Loss: 0.2610 Acc: 0.4578\n",
            "valid Loss: 0.3455 Acc: 0.3141\n",
            "\n",
            "Epoch 6/23\n",
            "----------\n",
            "train Loss: 0.2477 Acc: 0.4833\n",
            "valid Loss: 0.3379 Acc: 0.3376\n",
            "\n",
            "Epoch 7/23\n",
            "----------\n",
            "train Loss: 0.2377 Acc: 0.5006\n",
            "valid Loss: 0.3289 Acc: 0.3562\n",
            "\n",
            "Epoch 8/23\n",
            "----------\n",
            "train Loss: 0.2385 Acc: 0.5011\n",
            "valid Loss: 0.3433 Acc: 0.3155\n",
            "\n",
            "Epoch 9/23\n",
            "----------\n",
            "train Loss: 0.2351 Acc: 0.5074\n",
            "valid Loss: 0.3420 Acc: 0.3203\n",
            "\n",
            "Epoch 10/23\n",
            "----------\n",
            "train Loss: 0.2349 Acc: 0.4999\n",
            "valid Loss: 0.3363 Acc: 0.3334\n",
            "\n",
            "Epoch 11/23\n",
            "----------\n",
            "train Loss: 0.2328 Acc: 0.5132\n",
            "valid Loss: 0.3355 Acc: 0.3338\n",
            "\n",
            "Epoch 12/23\n",
            "----------\n",
            "train Loss: 0.2304 Acc: 0.5149\n",
            "valid Loss: 0.3533 Acc: 0.2910\n",
            "\n",
            "Epoch 13/23\n",
            "----------\n",
            "train Loss: 0.2302 Acc: 0.5126\n",
            "valid Loss: 0.3181 Acc: 0.3673\n",
            "\n",
            "Epoch 14/23\n",
            "----------\n",
            "train Loss: 0.2293 Acc: 0.5146\n",
            "valid Loss: 0.3188 Acc: 0.3693\n",
            "\n",
            "Epoch 15/23\n",
            "----------\n",
            "train Loss: 0.2304 Acc: 0.5163\n",
            "valid Loss: 0.3242 Acc: 0.3656\n",
            "\n",
            "Epoch 16/23\n",
            "----------\n",
            "train Loss: 0.2259 Acc: 0.5217\n",
            "valid Loss: 0.3113 Acc: 0.3832\n",
            "\n",
            "Epoch 17/23\n",
            "----------\n",
            "train Loss: 0.2281 Acc: 0.5172\n",
            "valid Loss: 0.3320 Acc: 0.3435\n",
            "\n",
            "Epoch 18/23\n",
            "----------\n",
            "train Loss: 0.2280 Acc: 0.5209\n",
            "valid Loss: 0.3234 Acc: 0.3624\n",
            "\n",
            "Epoch 19/23\n",
            "----------\n",
            "train Loss: 0.2284 Acc: 0.5146\n",
            "valid Loss: 0.3162 Acc: 0.3642\n",
            "\n",
            "Epoch 20/23\n",
            "----------\n",
            "train Loss: 0.2287 Acc: 0.5189\n",
            "valid Loss: 0.3216 Acc: 0.3621\n",
            "\n",
            "Epoch 21/23\n",
            "----------\n",
            "train Loss: 0.2271 Acc: 0.5266\n",
            "valid Loss: 0.3363 Acc: 0.3262\n",
            "\n",
            "Epoch 22/23\n",
            "----------\n",
            "train Loss: 0.2298 Acc: 0.5167\n",
            "valid Loss: 0.3284 Acc: 0.3517\n",
            "\n",
            "Epoch 23/23\n",
            "----------\n",
            "train Loss: 0.2277 Acc: 0.5180\n",
            "valid Loss: 0.3320 Acc: 0.3424\n",
            "\n",
            "Training complete in 4m 53s\n",
            "Best val Acc: 0.383155\n",
            "Accuracy of female_angry : 15 %\n",
            "Accuracy of female_disgust : 19 %\n",
            "Accuracy of female_fear : 46 %\n",
            "Accuracy of female_happy :  8 %\n",
            "Accuracy of female_neutral : 11 %\n",
            "Accuracy of female_sad : 16 %\n",
            "Accuracy of female_surprise :  9 %\n",
            "Accuracy of male_angry : 14 %\n",
            "Accuracy of male_disgust : 31 %\n",
            "Accuracy of male_fear : 25 %\n",
            "Accuracy of male_happy : 10 %\n",
            "Accuracy of male_neutral :  8 %\n",
            "Accuracy of male_sad : 12 %\n",
            "Accuracy of male_surprise :  1 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JL0q54xUYxso",
        "colab_type": "text"
      },
      "source": [
        "#Mel Spectrogram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u29hO8XLfQUM",
        "colab_type": "text"
      },
      "source": [
        "1. Best val Acc: 0.396617\n",
        "\n",
        "2. Best val Acc: 0.136003"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMA0zDJ8Y28f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "356c0d9f-4ffb-40b6-e276-4d02a5a3fe65"
      },
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "with open(\"/gdrive/My Drive/mel_crema.pkl\", 'rb') as f:\n",
        "    mel_c = pickle.load(f)\n",
        "\n",
        "with open(\"/gdrive/My Drive/mel_3.pkl\", 'rb') as f:\n",
        "    mel_3 = pickle.load(f)\n",
        "\n",
        "print(mel_c.shape)\n",
        "print(mel_3.shape)\n",
        "\n",
        "ref = pd.read_csv(\"/gdrive/My Drive/Data_path.csv\")\n",
        "ref = ref.drop(11586)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7062, 30, 216, 1)\n",
            "(4524, 30, 216, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ft2kp--_ZJ5B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f66a66f6-f047-493e-c523-df29929513c5"
      },
      "source": [
        "mel = np.concatenate((mel_3, mel_c), axis=0)\n",
        "mel.shape"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11586, 30, 216, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SS_RtuSBbJiP",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(mel, ref.labels, test_size=0.25, shuffle=True, random_state=42)\n",
        "\n",
        "\n",
        "# one hot encode the target \n",
        "lb = LabelEncoder()\n",
        "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
        "y_test = np_utils.to_categorical(lb.fit_transform(y_test))\n",
        "\n",
        "# Normalization as per the standard NN process\n",
        "mean = np.mean(X_train, axis=0)\n",
        "std = np.std(X_train, axis=0)\n",
        "\n",
        "X_train = (X_train - mean)/std\n",
        "X_test = (X_test - mean)/std"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sp95ueVRoG6-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(mel, ref.labels, test_size=0.25, shuffle=True, random_state=42)\n",
        "\n",
        "\n",
        "# one hot encode the target \n",
        "lb = LabelEncoder()\n",
        "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
        "y_test = np_utils.to_categorical(lb.fit_transform(y_test))\n",
        "\n",
        "#other normalization\n",
        "max_data = np.max(X_train)\n",
        "min_data = np.min(X_train)\n",
        "X_train = (X_train-min_data)/(max_data-min_data+1e-6)\n",
        "X_train =  X_train-0.5\n",
        "\n",
        "max_data = np.max(X_test)\n",
        "min_data = np.min(X_test)\n",
        "X_test = (X_test-min_data)/(max_data-min_data+1e-6)\n",
        "X_test =  X_test-0.5"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lkFv_QcpcHIM",
        "colab": {}
      },
      "source": [
        "train_dataset = myDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size= 6, shuffle=True)\n",
        "\n",
        "valid_dataset = myDataset(X_test, y_test)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size= 6, shuffle=True)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a-CZv01KbJig",
        "colab": {}
      },
      "source": [
        "model_ft = Emo2DNet(30)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model_ft = model_ft.cuda()"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "At4lo4kabJis",
        "colab": {}
      },
      "source": [
        "dataset_sizes = {'train':len(train_loader.dataset),'valid':len(valid_loader.dataset)}\n",
        "dataloaders = {'train':train_loader,'valid':valid_loader}"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eH5MWI4BeFJq",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.01\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uFkK5t_0bJiy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1a329d35-038f-4019-fb70-10942700bf0d"
      },
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=24)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/23\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.1593 Acc: 0.6524\n",
            "valid Loss: 0.4913 Acc: 0.1488\n",
            "\n",
            "Epoch 1/23\n",
            "----------\n",
            "train Loss: 0.1579 Acc: 0.6516\n",
            "valid Loss: 0.5652 Acc: 0.0970\n",
            "\n",
            "Epoch 2/23\n",
            "----------\n",
            "train Loss: 0.1553 Acc: 0.6588\n",
            "valid Loss: 0.5787 Acc: 0.1222\n",
            "\n",
            "Epoch 3/23\n",
            "----------\n",
            "train Loss: 0.1565 Acc: 0.6523\n",
            "valid Loss: 0.5848 Acc: 0.1046\n",
            "\n",
            "Epoch 4/23\n",
            "----------\n",
            "train Loss: 0.1557 Acc: 0.6621\n",
            "valid Loss: 0.6401 Acc: 0.0894\n",
            "\n",
            "Epoch 5/23\n",
            "----------\n",
            "train Loss: 0.1503 Acc: 0.6757\n",
            "valid Loss: 0.6619 Acc: 0.1056\n",
            "\n",
            "Epoch 6/23\n",
            "----------\n",
            "train Loss: 0.1495 Acc: 0.6710\n",
            "valid Loss: 0.6061 Acc: 0.1267\n",
            "\n",
            "Epoch 7/23\n",
            "----------\n",
            "train Loss: 0.1489 Acc: 0.6688\n",
            "valid Loss: 0.6464 Acc: 0.1025\n",
            "\n",
            "Epoch 8/23\n",
            "----------\n",
            "train Loss: 0.1469 Acc: 0.6755\n",
            "valid Loss: 0.7511 Acc: 0.0918\n",
            "\n",
            "Epoch 9/23\n",
            "----------\n",
            "train Loss: 0.1326 Acc: 0.7080\n",
            "valid Loss: 0.6465 Acc: 0.0953\n",
            "\n",
            "Epoch 10/23\n",
            "----------\n",
            "train Loss: 0.1297 Acc: 0.7155\n",
            "valid Loss: 0.6589 Acc: 0.0932\n",
            "\n",
            "Epoch 11/23\n",
            "----------\n",
            "train Loss: 0.1267 Acc: 0.7195\n",
            "valid Loss: 0.6327 Acc: 0.1018\n",
            "\n",
            "Epoch 12/23\n",
            "----------\n",
            "train Loss: 0.1279 Acc: 0.7190\n",
            "valid Loss: 0.6175 Acc: 0.1094\n",
            "\n",
            "Epoch 13/23\n",
            "----------\n",
            "train Loss: 0.1262 Acc: 0.7251\n",
            "valid Loss: 0.5886 Acc: 0.1101\n",
            "\n",
            "Epoch 14/23\n",
            "----------\n",
            "train Loss: 0.1250 Acc: 0.7247\n",
            "valid Loss: 0.6211 Acc: 0.0935\n",
            "\n",
            "Epoch 15/23\n",
            "----------\n",
            "train Loss: 0.1229 Acc: 0.7280\n",
            "valid Loss: 0.6146 Acc: 0.1125\n",
            "\n",
            "Epoch 16/23\n",
            "----------\n",
            "train Loss: 0.1215 Acc: 0.7337\n",
            "valid Loss: 0.5845 Acc: 0.1198\n",
            "\n",
            "Epoch 17/23\n",
            "----------\n",
            "train Loss: 0.1213 Acc: 0.7303\n",
            "valid Loss: 0.6062 Acc: 0.1212\n",
            "\n",
            "Epoch 18/23\n",
            "----------\n",
            "train Loss: 0.1204 Acc: 0.7356\n",
            "valid Loss: 0.5833 Acc: 0.1056\n",
            "\n",
            "Epoch 19/23\n",
            "----------\n",
            "train Loss: 0.1192 Acc: 0.7415\n",
            "valid Loss: 0.5798 Acc: 0.1312\n",
            "\n",
            "Epoch 20/23\n",
            "----------\n",
            "train Loss: 0.1183 Acc: 0.7383\n",
            "valid Loss: 0.5696 Acc: 0.1419\n",
            "\n",
            "Epoch 21/23\n",
            "----------\n",
            "train Loss: 0.1193 Acc: 0.7360\n",
            "valid Loss: 0.6138 Acc: 0.1115\n",
            "\n",
            "Epoch 22/23\n",
            "----------\n",
            "train Loss: 0.1183 Acc: 0.7392\n",
            "valid Loss: 0.5881 Acc: 0.1343\n",
            "\n",
            "Epoch 23/23\n",
            "----------\n",
            "train Loss: 0.1193 Acc: 0.7376\n",
            "valid Loss: 0.5541 Acc: 0.1332\n",
            "\n",
            "Training complete in 5m 21s\n",
            "Best val Acc: 0.148775\n",
            "Accuracy of female_angry : 12 %\n",
            "Accuracy of female_disgust : 17 %\n",
            "Accuracy of female_fear : 48 %\n",
            "Accuracy of female_happy :  4 %\n",
            "Accuracy of female_neutral :  8 %\n",
            "Accuracy of female_sad : 11 %\n",
            "Accuracy of female_surprise :  3 %\n",
            "Accuracy of male_angry :  8 %\n",
            "Accuracy of male_disgust : 31 %\n",
            "Accuracy of male_fear : 26 %\n",
            "Accuracy of male_happy :  7 %\n",
            "Accuracy of male_neutral :  1 %\n",
            "Accuracy of male_sad :  7 %\n",
            "Accuracy of male_surprise :  0 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2mFEMO6AGst",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}